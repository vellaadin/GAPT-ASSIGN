<!DOCTYPE html>
<html lang = "en">
<head>
  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="description" content="Emotion-driven music player through webcam facial detection and expression recognition">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <link rel="icon" href="{{ url_for('static', filename='assets/icon.png') }}">
  <title>yourTunes</title>

  <link rel="preconnect" href="https://fonts.googleapis.com">
  <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@400;700&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Workbench&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Orbitron&family=Workbench&display=swap" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css2?family=Ubuntu&display=swap" rel="stylesheet">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/style.css') }}">

  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest/dist/tf.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@teachablemachine/image@latest/dist/teachablemachine-image.min.js"></script>
  <script src="{{ url_for('static', filename='scripts/utils.js') }}"></script>
  <script src="{{ url_for('static', filename='scripts/faceDetection.js') }}"></script>
  <script src="{{ url_for('static', filename='scripts/emotionPrediction.js') }}"></script>
  <script src="{{ url_for('static', filename='scripts/music.js') }}"></script>
  <script src="{{ url_for('static', filename='scripts/main.js') }}"></script>
  <script async src="https://docs.opencv.org/4.5.4/opencv.js" onload="openCVLoaded()" type="text/javascript"></script>
</head>

<body>
  <!-- Title -->
  <div class = "title-container" id="page-title">
    <h1 class="title">yourTunes - An Emotion-Driven Music Player</h1>
  </div>

  <!-- Modal Error box -->
  <div id="modalPopup" class="modal">
    <div class="modal-content">
      <span class="close">&times;</span>
      <p id="modal-message"></p>
    </div>
  </div>

  <!-- Playback and buttons -->
  <div id="webcam-section">
    <div class="vertical-container">
      <!-- buttons -->
      <div id = "buttons" class="vertical-container">
        <div class = "buttonSet">
          <!-- Enable/Disable Webcam Buttons -->
          <button id="toggleCam" onclick="toggleWebcam()">Enable Webcam</button>
          <!-- Start/Stop Buttons -->
          <button id="toggleMusicSelection" onclick="toggleMusicSelection()">Start</button>
          <!-- Toggle Display button -->
          <button id="toggleDisplay" onclick="toggleDisplay()">Hide Display</button>
        </div>
        <div class = "buttonSet" id="extraButtons" style="display: none;">
          <!-- Show facial detection visualisation -->
          <button id="toggleBoundingBoxes" onclick="toggleBoundingBoxes()">Draw Bounding boxes</button>
          <!-- Show cropped face -->
          <button id="toggleCroppedFace" onclick="toggleCroppedFace()">Show Cropped Face</button>
          <!-- Show Classification labels -->
          <button id="toggleLabels" onclick="toggleLabels()">Show Labels</button>
        </div>
      </div>

      <div id="emotion-container"  style="display: none;">
        <h2 id="emotion">Placeholder Emotion</h2>
      </div>

      <div id="cropped-face-container" style="display: none;">
        <h2>Cropped Face</h2>
        <canvas id="croppedFaceCanvas" width="224" height="224"></canvas>
        <div id="croppedFacePlaceholder" style="display: none;">
          <p>No Face Detected</p>
        </div>
      </div>


      <!-- Playback and labels -->
      <div class ="horizontal-container" id="webcam-and-labels-container">
        <!-- Video playback -->
        <div id="webcam-placeholder">
          <p> Click Enable Webcam to view playback!</p>
        </div>
        <div id="webcam-container" style="display: none;">
          <video id="webcamPlayback" autoplay playsinline width="640" height="480"></video>
        </div>
        <div id="opencv-container" style="display: none;">
          <canvas id="canvasOutput" width="640" height="480"></canvas>
        </div>
        <!-- Labels -->
        <div class = "vertical-container" id="side-container">
          <h3>Labels:</h2>
          <div id="label-container"></div>
        </div>
      </div>
    </div>
  </div>

  <!-- Music Area -->
  <div id="music-section">
    <h2>Music</h2>
    <div id="musicMessage">What mood are you in?</div> <!-- Message container -->
    <div id="musicPlaceHolder">                                                                                                             
      <iframe id="musicPlayerIframe" style="border-radius:10px; padding:20px" src="" width="100%" height="100%" frameborder="0" allow="autoplay; clipboard-write; encrypted-media; fullscreen; picture-in-picture" loading="lazy"></iframe>
    </div>
    <div id="emotionScores" style="display: none;">
      <h3>Emotion Scores:</h3>
      <table id="emotionTable">
        <thead>
          <tr id="emotionTableHeader"></tr>
          <tr id="emotionTableData"></tr>
        </thead>
        <tbody></tbody>
      </table>
    </div>
  </div>

  <!-- Info Area -->
  <div id="info-area">

    <div id="hide-info">Hide</div>

    <div class="info-group">
      <h2>What is this?</h2>
      <p>
        <span class="highlight">yourTunes</span> is an emotion-driven music player that uses your webcam to detect
        and identify your facial expressions using a machine learning model and plays music based on your mood.
      </p>
    </div>

    <div class="info-group">
      <h2>How does it work?</h2>
      <p>
        <span class="highlight">yourTunes</span> makes use of your webcam feed to find your face using 
        <a href="https://opencv.org/" target="_blank"> OpenCV </a> and then uses a machine learning model
        trained using <a href="https://teachablemachine.withgoogle.com/" target="_blank"> Google Teachable Machine </a>
        to identify your facial expression. The model then uses this information to play music from a curated selection
        based on your mood.
      </p>
    </div>

    <div class="info-group">
      <h2>Why was it made?</h2>
      <p>
        <span class="highlight">yourTunes</span> was made as a project for the GAPT course at the University of Malta.
        It was made to demonstrate the use of machine learning and computer vision in a real world application.
      </p>
    </div>

  </div>

  <footer>
    <p> GAPT Project by Andrea, Jeremy & Adin </p>
    <p><a id="info-button" href="#info-area"> Click Here to find out More... </a></p>
  </footer>
</body>
</html>